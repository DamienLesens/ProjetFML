{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63d95533-10b2-4b55-96aa-119b2a26c059",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import skimage.measure\n",
    "from scipy import signal\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e44bc39b-3919-4d9d-9fe8-90cb8fe9a363",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_path = str(os.getcwd())\n",
    "X_train = np.load(my_path+'/.data/X_train_surge_new.npz')\n",
    "X_train_slp = X_train['slp']\n",
    "X_train_surge1 = X_train['surge1_input']\n",
    "X_train_surge2 = X_train['surge2_input']\n",
    "X_train_surge = [None,X_train_surge1,X_train_surge2]\n",
    "Y_train = np.array(pd.read_csv(my_path+'/.data/Y_train_surge.csv'))\n",
    "X_test = np.load(my_path+'/.data/X_test_surge_new.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a3349b7-1b08-458a-b5ed-b96534d0c6de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def surge_prediction_metric(dataframe_y_true, dataframe_y_pred):\n",
    "    weights = np.linspace(1, 0.1, 10)[np.newaxis]\n",
    "    surge1_columns = [\n",
    "        'surge1_t0', 'surge1_t1', 'surge1_t2', 'surge1_t3', 'surge1_t4',\n",
    "        'surge1_t5', 'surge1_t6', 'surge1_t7', 'surge1_t8', 'surge1_t9' ]\n",
    "    surge2_columns = [\n",
    "        'surge2_t0', 'surge2_t1', 'surge2_t2', 'surge2_t3', 'surge2_t4',\n",
    "        'surge2_t5', 'surge2_t6', 'surge2_t7', 'surge2_t8', 'surge2_t9' ]\n",
    "    surge1_score = (weights * (dataframe_y_true[surge1_columns].values - dataframe_y_pred[surge1_columns].values)**2).mean()\n",
    "    surge2_score = (weights * (dataframe_y_true[surge2_columns].values - dataframe_y_pred[surge2_columns].values)**2).mean()\n",
    "\n",
    "    return surge1_score + surge2_score\n",
    "\n",
    "def metric_one_surge(y_true,y_pred):\n",
    "    weights = np.linspace(1, 0.1, 10)[np.newaxis]\n",
    "    score = (weights*(y_true-y_pred)**2).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b626eaa-c95a-4311-8f60-8c52de859bd9",
   "metadata": {},
   "source": [
    "### Utilitary functions for ruling 'weights' issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54fd427b-afa4-4eea-9dde-24652156c651",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# should be applied to Y_train before learning\n",
    "def transform(y):\n",
    "    weights = np.sqrt(np.linspace(1, 0.1, 10)[np.newaxis])\n",
    "    return weights*y\n",
    "\n",
    "# should be applied to Y_pred after test\n",
    "def inverse_transform(y):\n",
    "    weights = 1/np.sqrt(np.linspace(1, 0.1, 10)[np.newaxis])\n",
    "    return weights*y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0d6217-a638-47f6-9945-9198012402a2",
   "metadata": {},
   "source": [
    "## Use CNN only on pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eeb1d4e-2171-4e0e-b509-1fd7c2b9c0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([[1, 2, 1],\n",
    "                   [2, 4, 2],\n",
    "                   [1, 2, 1]])\n",
    "kernel = (1/kernel.sum()) * kernel\n",
    "\n",
    "def dimReduceConv(img, nbsteps):\n",
    "    for i in range(nbsteps):\n",
    "        # gaussian convolution\n",
    "        img = signal.convolve2d(img, kernel)\n",
    "        # max pooling\n",
    "        img = skimage.measure.block_reduce(img, (2,2), np.max)\n",
    "    img = signal.convolve2d(img, kernel)\n",
    "    return img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07400dd1-8105-4765-9c4d-c62f822746f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def slp_to_flat_images(slp):\n",
    "    a,b,c,d = np.shape(slp)\n",
    "    return slp.reshape((a*b,c,d))\n",
    "\n",
    "class Preprocess:\n",
    "    \n",
    "    _scaler1 = StandardScaler()\n",
    "    _scaler2 = StandardScaler()\n",
    "    \n",
    "    def fit_transform(self,slp,nb_levels):\n",
    "        #reshape\n",
    "        list_flat_images = slp_to_flat_images(slp)\n",
    "\n",
    "        #normalize\n",
    "        list_flat_images = self._scaler1.fit_transform(list_flat_images.reshape(-1, list_flat_images.shape[-1])).reshape(list_flat_images.shape)\n",
    "        \n",
    "        self.nblevels = nb_levels\n",
    "        \n",
    "        # convolve\n",
    "        slp_LD = []\n",
    "        for img in list_flat_images:\n",
    "            flatImg = dimReduceConv(img,nb_levels).flatten()\n",
    "            slp_LD.append(flatImg)\n",
    "        \n",
    "        # reshape array\n",
    "        slp_LD = np.array([np.concatenate(slp_LD[i*40:(i+1)*40]) for i in range(len(slp))])\n",
    "        \n",
    "        #renormalize\n",
    "        slp_LD = self._scaler2.fit_transform(slp_LD)\n",
    "        \n",
    "        return slp_LD\n",
    "    \n",
    "    def transform(self,slp):\n",
    "        flat = slp_to_flat_images(slp)\n",
    "        flat = self._scaler1.transform(flat.reshape(-1, flat.shape[-1])).reshape(flat.shape)\n",
    "\n",
    "        # convolve\n",
    "        slp_LD = []\n",
    "        for img in flat:\n",
    "            flatImg = dimReduceConv(img,self.nblevels).flatten()\n",
    "            slp_LD.append(flatImg)\n",
    "                          \n",
    "        slp_LD = np.array([np.concatenate(slp_LD[i*40:(i+1)*40]) for i in range(len(slp))])\n",
    "        slp_LD = self._scaler2.transform(slp_LD)\n",
    "        # print(slp_LD.shape)\n",
    "        # print(slp_LD.shape)\n",
    "        return slp_LD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee1bb30d-ac09-493b-961b-6cbaedb1c130",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#preprocessing (convolutions and scaling) done once for all\u001b[39;00m\n\u001b[1;32m     31\u001b[0m prepro \u001b[38;5;241m=\u001b[39m Preprocess()\n\u001b[0;32m---> 32\u001b[0m slp_train_LD[s] \u001b[38;5;241m=\u001b[39m \u001b[43mprepro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslp_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbConv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m slp_test_LD[s] \u001b[38;5;241m=\u001b[39m prepro\u001b[38;5;241m.\u001b[39mtransform(slp_test)\n\u001b[1;32m     35\u001b[0m y_train[s] \u001b[38;5;241m=\u001b[39m transform(surge_output_train)\n",
      "Cell \u001b[0;32mIn [6], line 22\u001b[0m, in \u001b[0;36mPreprocess.fit_transform\u001b[0;34m(self, slp, nb_levels)\u001b[0m\n\u001b[1;32m     20\u001b[0m slp_LD \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m list_flat_images:\n\u001b[0;32m---> 22\u001b[0m     flatImg \u001b[38;5;241m=\u001b[39m \u001b[43mdimReduceConv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnb_levels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     23\u001b[0m     slp_LD\u001b[38;5;241m.\u001b[39mappend(flatImg)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# reshape array\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [5], line 11\u001b[0m, in \u001b[0;36mdimReduceConv\u001b[0;34m(img, nbsteps)\u001b[0m\n\u001b[1;32m      9\u001b[0m     img \u001b[38;5;241m=\u001b[39m signal\u001b[38;5;241m.\u001b[39mconvolve2d(img, kernel)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# max pooling\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mskimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeasure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m img \u001b[38;5;241m=\u001b[39m signal\u001b[38;5;241m.\u001b[39mconvolve2d(img, kernel)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skimage/measure/block.py:84\u001b[0m, in \u001b[0;36mblock_reduce\u001b[0;34m(image, block_size, func, cval, func_kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m         after_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     82\u001b[0m     pad_width\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;241m0\u001b[39m, after_width))\n\u001b[0;32m---> 84\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconstant\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m               \u001b[49m\u001b[43mconstant_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m blocked \u001b[38;5;241m=\u001b[39m view_as_blocks(image, block_size)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(blocked, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mrange\u001b[39m(image\u001b[38;5;241m.\u001b[39mndim, blocked\u001b[38;5;241m.\u001b[39mndim)),\n\u001b[1;32m     90\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mpad\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/arraypad.py:793\u001b[0m, in \u001b[0;36mpad\u001b[0;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m stat_functions \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximum\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mamax, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimum\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mamin,\n\u001b[1;32m    789\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mmean, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mmedian}\n\u001b[1;32m    791\u001b[0m \u001b[38;5;66;03m# Create array with final shape and original values\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;66;03m# (padded area is undefined)\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m padded, original_area_slice \u001b[38;5;241m=\u001b[39m \u001b[43m_pad_simple\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_width\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;66;03m# And prepare iteration over all dimensions\u001b[39;00m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;66;03m# (zipping may be more readable than using enumerate)\u001b[39;00m\n\u001b[1;32m    796\u001b[0m axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(padded\u001b[38;5;241m.\u001b[39mndim)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/arraypad.py:120\u001b[0m, in \u001b[0;36m_pad_simple\u001b[0;34m(array, pad_width, fill_value)\u001b[0m\n\u001b[1;32m    117\u001b[0m     padded\u001b[38;5;241m.\u001b[39mfill(fill_value)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# Copy old array into correct space\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m original_area_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mslice\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_width\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m padded[original_area_slice] \u001b[38;5;241m=\u001b[39m array\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m padded, original_area_slice\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/arraypad.py:121\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    117\u001b[0m     padded\u001b[38;5;241m.\u001b[39mfill(fill_value)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# Copy old array into correct space\u001b[39;00m\n\u001b[1;32m    120\u001b[0m original_area_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;43mslice\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m size, (left, right) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(array\u001b[38;5;241m.\u001b[39mshape, pad_width)\n\u001b[1;32m    123\u001b[0m )\n\u001b[1;32m    124\u001b[0m padded[original_area_slice] \u001b[38;5;241m=\u001b[39m array\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m padded, original_area_slice\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# prepare validation dataset (extract test from the data we have)\n",
    "nbs = 10 #number of splits to do the average on\n",
    "test_s = 0.1 # size of test sample\n",
    "\n",
    "ss = ShuffleSplit(n_splits=nbs,test_size=test_s)\n",
    "X_ind = np.zeros(5599)\n",
    "\n",
    "# parameters for test\n",
    "city=1\n",
    "nbConv=3\n",
    "\n",
    "surge_input_train = [None] * 10\n",
    "surge_input_test = [None] * 10\n",
    "surge_output_test = [None] * 10\n",
    "slp_train_LD = [None] * 10\n",
    "slp_test_LD = [None] * 10\n",
    "y_train = [None] * 10\n",
    "\n",
    "for s, (train_index, test_index) in enumerate(ss.split(X_ind)):\n",
    "    #split data\n",
    "    slp_train = X_train_slp[train_index]\n",
    "    slp_test = X_train_slp[test_index]\n",
    "\n",
    "    surge_input_train[s] = X_train_surge[city][train_index]\n",
    "    surge_input_test[s] = X_train_surge[city][test_index]\n",
    "\n",
    "    surge_output_train = Y_train[train_index,1:11] if city==1 else Y_train[train_index,11:]\n",
    "    surge_output_test[s] = Y_train[test_index,1:11] if city==1 else Y_train[test_index,11:]\n",
    "\n",
    "    #preprocessing (convolutions and scaling) done once for all\n",
    "    prepro = Preprocess()\n",
    "    slp_train_LD[s] = prepro.fit_transform(slp_train, nbConv)\n",
    "    slp_test_LD[s] = prepro.transform(slp_test)\n",
    "\n",
    "    y_train[s] = transform(surge_output_train)\n",
    "\n",
    "\n",
    "# function to call for cross validate a parameter\n",
    "def testParams(learningRate=1e-5, hiddenLayers=(100,),slv='sgd',activ_fun='relu'):\n",
    "    \n",
    "    errors = []\n",
    "    \n",
    "    for s in range(nbs):\n",
    "        print(s)\n",
    "        \n",
    "        #concatenate slp and surge input\n",
    "        x_train = np.concatenate((surge_input_train, slp_train_LD), axis=1)\n",
    "        x_test = np.concatenate((surge_input_test, slp_test_LD), axis=1)\n",
    "        \n",
    "        print(x_train.shape)\n",
    "        \n",
    "        #learn\n",
    "        clf = MLPRegressor(solver=slv, hidden_layer_sizes=((10+10+40*dimPCA)//2,), \n",
    "                           alpha=learningRate, max_iter=1000, activation=activ_fun)\n",
    "        clf.fit(x_train,transform(y_train))\n",
    "        \n",
    "        #predict\n",
    "        y_pred = inverse_transform(clf.predict(x_test))\n",
    "        \n",
    "        error = metric_one_surge(surge_output_test,y_pred)\n",
    "        errors.append(error)\n",
    "        print(\"error :\",error)\n",
    "    \n",
    "    print(learningRate,errors)\n",
    "    return errors    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1422cc-162f-429d-931f-0e1e49460dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "testParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b52b60-76c9-440a-bf5c-8e62939418ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
